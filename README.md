
Alex Context NLG Dataset
========================

* **Authors**: Ondřej Dušek, Filip Jurčíček
* **License**: [Creative Commons 4.0 BY-SA](https://creativecommons.org/licenses/by-sa/4.0/)

This is a dataset for NLG in the English Public Transport Information domain which contains 
preceding context (user utterance) along with each data instance (pair of source meaning 
representation and target natural language paraphrases). This allows NLG systems train on this 
dataset to entrain (adapt) to the preceding utterance, i.e., reuse wording and syntactic structure.

More information can be found in the following paper:

* Ondřej Dušek and Filip Jurčíček: *A Context-aware Natural Language Generation Dataset for 
    Dialogue Systems*. In: RE-WOCHAT, LREC 2016.


Dataset format
--------------

The dataset is released in CSV and JSON formats; the contents are identical. Both files use the 
UTF-8 encoding.

The dataset contains 1859 instances. Each instance has the following properties:

* `context_utt` -- the context user utterance (the utterance preceding to the response to be 
    generated, typically user's question the dialogue system wants to answer). Manual call 
    transcription was used to obtain the contexts.
* `context_freq` -- frequency of the context utterance within our recorded calls (each distinct 
    context is only included once per response type).
* `context_parse` -- SLU parse of the transcribed context utterance.
* `response_da` -- response semantics (dialogue act) generated by our rule-based bigram policy. 
    There may be more responses for the same context; they are stored as separate instances.
* `response_nl` -- response natural language paraphrases. Three paraphrases have been collected on 
    CrowdFlower and checked for errors. They are stored as `response_nl1`, `response_nl2`, 
    and `response_nl3` in the CSV file.

All properties exist in the default (delexicalized) version and a lexicalized version (with the `-l`
suffix). The lexicalized version was used in CrowdFlower tasks.

### The domain ###

The domain is public transport by bus or subway among New York City subway stations
on Manhattan. The users may specify origin and destination stops, departure time, and means of
transport. After a connection is provided, they may ask about its duration, distance, or arrival 
time, and number of transfers. For simplicity, directions provided in the dataset do not involve
any transfers.

### Dialogue acts format ###

The dialogue acts in this dataset (`context_parse` and `response_da` properties) follow the [Alex
dialogue act format](https://github.com/UFAL-DSG/alex/blob/master/alex/doc/ufal-dialogue-acts.rst).
Basically, it is a sequence of *dialogue act items*. Each dialogue act item contains an act type
and may also contain a slot and a value.

**Examples**:

| dialogue act                                          | example utterance                   |
| ------------------------------------------------------|-------------------------------------|
| `hello()`                                             | *Hi.*                               |
| `request(from_stop)`                                  | *Where are you coming from?*        |
| `inform(departure_time="7:00")&inform(ampm="pm")`     | *I want departure at 7 pm.*         |
| `iconfirm(to_stop="Central Park")&request(from_stop)` | *OK, from Central Park. Where to?*  |

The **act types used** in this dataset are:
* `inform` -- informing about a connection or a specific detail (distance, arrival time)
* `inform_no_match` -- apology that a route has not been found
* `iconfirm` -- confirmation of user-specified route parameters
* `request` -- request for additional details to complete the route search (origin or destination 
    stop)

**Slots used** in this dataset are:
* `from_stop` -- the origin stop
* `to_stop` -- the destination stop
* `direction` -- heading/direction of the bus or subway (used when providing directions)
* `departure_time` -- departure time (absolute, e.g. *7:00*)
* `departure_time_rel` -- departure time (relative, e.g. *in 10 minutes*)
* `ampm` -- daytime (AM/PM, morning or afternoon). This is merged with the departure time when
    giving directions, but separate for confirmations/apologies.
* `vehicle` -- means of transport (bus/subway)
* `line` -- bus or subway line in question (used when providing directions)
* `arrival_time` -- arrival time (absolute; only provided on special request)
* `duration` -- duration of the travel (only provided on special request)
* `distance` -- distance of the travel (only provided on special request)
* `num_transfers` -- number of transfers on the route (only provided on special request)
* `alternative` -- connection variant (next, previous, *n*-th)

### Delexicalization limits ###

Even though the delexicalized versions of all dataset items only contain `*SLOT` placeholders 
instead of each slot value, the delexicalization has had its limits. These must be observed to 
generate fluent utterances using this dataset:

* The `ampm` slot may contain either the expressions *am*/*pm*, or daytime indication such as 
    *morning*, *afternoon* or *evening*. The abbreviated expressions show a different behavior
    than the full words (e.g., *7:00 pm* and *7:00 in the evening* is OK, but *7:00 in the pm* 
    is not). This must be checked for when filling the values instead of the placeholder.

* The `ampm` slot is sometimes doubled, as in *7:00 pm in the evening* or *7:00 pm evening*;
    the delexicalization resulted in `*DEPARTURE_TIME *AMPM in the *AMPM` and so on.

* The `num_transfers` slot was used with the values *0*, *1*, *2* in the development of the 
    dataset. Each of these values exhibits a slightly different behavior, so a generated sentence
    might need to be adapted to the concrete value.

* The `alternative` slot has only been delexicalized when its value numeric (e.g., 
    *second option*). The usage of ordinal numerals is indicated by using the `*ALTERNATIVE-th` 
    placeholder, cardinal numerals do not have the `-th` suffix. 
    The utterances for `alternative=next`, `alternative=previous`, and `alternative=last` have 
    not been delexicalized as different expressions can be used and underlie entrainment.


Dataset development (technical manual)
--------------------------------------

This documents the development of the dataset and can be adapted for the development of similar
datasets in different domains.

The [Alex spoken dialogue systems framework](https://github.com/UFAL-DSG/alex) is required for the 
development. All scripts relating to the dataset development are located in the 
`alex/tools/reparse/` and `alex/tools/crowdflower/nlg_job` subdirectories.

### Preparing the data for CrowdFlower ###

We assume that in-domain calls have been recorded and transcribed, and are located in `<call-dir>`.

1) Extracting texts from transcribed dialogues:

    alex/tools/reparse/extract_texts.py <call-dir> > src/texts.tsv

2) Reparsing:

    alex/tools/reparse/reparse_en.py src/texts.tsv > reparse/reparse.tsv

3) Abstracting:

    alex/tools/reparse/abstract.sh reparse/reparse.tsv abstract/abstract.tsv

4) Generating reply tasks:

    alex/tools/crowdflower/nlg_job/generate_reply_tasks.py abstract/abstract.tsv > tasks/tasks.tsv
    (head -n 1 tasks/tasks.tsv && tail -n +2 tasks/tasks.tsv | shuf) > tasks/tasks-shuffled.tsv

   The reply tasks are shuffled so that they don't appear in a regular order on CrowdFlower
   (otherwise, CF users would always get very similar tasks in one batch).

### Running the CrowdFlower task ###



### Checking CrowdFlower results ###

### Assembling the dataset ###


